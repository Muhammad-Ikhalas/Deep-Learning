{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EnR2iRBqOSxG"},"outputs":[],"source":["!pip install torch numpy --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lsFHYyIbOrTu"},"outputs":[],"source":["import torch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"onHPz5zVOzzp"},"outputs":[],"source":["# Number\n","\n","t1 = torch.tensor(4.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"khpwA5IoPCDk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759269394,"user_tz":-300,"elapsed":45,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"45c5f6ff-254c-4da3-a680-7dfeba4161c7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":4}],"source":["t1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUPcPRsdPEGX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759269394,"user_tz":-300,"elapsed":37,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"cb0e1dea-ff2f-4bab-b97c-17afbdc5550b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":5}],"source":["t1.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FdXbzMtsPULT"},"outputs":[],"source":["#vector\n","t2=torch.tensor([1. , 2 , 3 , 4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVb8bxlBQoqW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759269395,"user_tz":-300,"elapsed":33,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"3f22a1a5-87fc-4c89-9e30-a75ab832b07b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 2., 3., 4.])"]},"metadata":{},"execution_count":7}],"source":["t2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8S2EHo8nQqCc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759269396,"user_tz":-300,"elapsed":30,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"4b26e603-65f2-45a5-85f4-d232064114d7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3.)"]},"metadata":{},"execution_count":8}],"source":["t2[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Et9xFfXOQ0Uf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759269397,"user_tz":-300,"elapsed":27,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"8079ab01-21c1-43a1-9be2-17db308d552a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.float32"]},"metadata":{},"execution_count":9}],"source":["t2[2].dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnR-VGnUQ9fP"},"outputs":[],"source":["#matrics\n","\n","t3 = torch.tensor([[1. , 2, 3],\n","                  [4 , 5 , 6],\n","                  [7,  8,  9]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IsOVj0wuRV33","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759269398,"user_tz":-300,"elapsed":24,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"8e9370ce-8d83-4b0f-b50e-19b09df1534a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 2., 3.],\n","        [4., 5., 6.],\n","        [7., 8., 9.]])"]},"metadata":{},"execution_count":11}],"source":["t3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlCBRpg0Rjfn"},"outputs":[],"source":["# 3-dimensional array\n","\n","t4 = torch.tensor([[[1., 2., 3.],\n","                   [4., 5., 6],\n","                   [7., 8, 9.]],\n","                  [[11., 12., 3.],\n","                   [14., 15., 16.],\n","                   [7, 18., 9]]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qepmTFndSNrf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759269399,"user_tz":-300,"elapsed":21,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"d99cff66-53e2-47f5-bffb-60f51a8e8e8b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 1.,  2.,  3.],\n","         [ 4.,  5.,  6.],\n","         [ 7.,  8.,  9.]],\n","\n","        [[11., 12.,  3.],\n","         [14., 15., 16.],\n","         [ 7., 18.,  9.]]])"]},"metadata":{},"execution_count":13}],"source":["t4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sksHIhk0SOxo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759269399,"user_tz":-300,"elapsed":18,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"93d08993-ccb1-4cf0-8535-1c45289f1069"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([])"]},"metadata":{},"execution_count":14}],"source":["# lets check the shap of the tensors\n","\n","t1.shape\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tC8z2ubqS9QX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270614,"user_tz":-300,"elapsed":1229,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"c3004d2a-01a4-43c8-a503-368cbee14e02"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4])"]},"metadata":{},"execution_count":15}],"source":["t2.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FeHGa1L8TDC4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270615,"user_tz":-300,"elapsed":34,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"e692218a-9c63-4a91-b643-0f111e475506"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 3])"]},"metadata":{},"execution_count":16}],"source":["t3.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-0SWDC5TEI1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270615,"user_tz":-300,"elapsed":31,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"70077cab-895c-4135-cde4-59bc88860cb2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 3, 3])"]},"metadata":{},"execution_count":17}],"source":["t4.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0A5HJSlpTGE2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270616,"user_tz":-300,"elapsed":29,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"8461a73d-15f6-45c7-c474-8349dbc9dda6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"]},"metadata":{},"execution_count":18}],"source":["# create tensors\n","\n","x = torch.tensor(3.)\n","w = torch.tensor(4. , requires_grad=True)\n","b = torch.tensor(5. , requires_grad=True)\n","x, w, b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwr4cs3SUFcv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270616,"user_tz":-300,"elapsed":26,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"82a49b2e-5b59-40c4-cc8e-546386eeb906"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(17., grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":19}],"source":["# Arithmetic operations\n","\n","y = w * x + b\n","\n","y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wHE8VUjUZaE"},"outputs":[],"source":["# compute derivative\n","\n","y.backward()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rxMl2wPYVrjP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270617,"user_tz":-300,"elapsed":24,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"04c6b0e7-8d59-458e-f125-9b3f26efecaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["dy/dx None\n","dy/dw tensor(3.)\n","dy/db tensor(1.)\n"]}],"source":["# Display Gradient\n","\n","print('dy/dx' , x.grad)\n","print('dy/dw' , w.grad)\n","print('dy/db' , b.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2dMjiofWZ8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270617,"user_tz":-300,"elapsed":21,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"83b86712-cf19-4a26-f617-edd7931453be"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2],\n","       [3, 4]])"]},"metadata":{},"execution_count":22}],"source":["import numpy as np\n","\n","x = np.array([[1, 2],\n","              [3, 4]])\n","\n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2W_nq_9efcB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270618,"user_tz":-300,"elapsed":19,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"d8bad6c2-696e-48b1-e12c-0d7e7d6e1ae5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 2],\n","        [3, 4]])"]},"metadata":{},"execution_count":23}],"source":["#conver the numpy array to a torch tensor.\n","\n","y = torch.from_numpy(x)\n","\n","y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gfCYIJwe_mS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270618,"user_tz":-300,"elapsed":16,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"54631347-5d7a-4807-f704-1bce6a61e331"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(dtype('int64'), torch.int64)"]},"metadata":{},"execution_count":24}],"source":["x.dtype , y.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJC-PUihfLAa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759270618,"user_tz":-300,"elapsed":13,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"2d640325-c75f-4c08-890f-15ceaa856dac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 2],\n","       [3, 4]])"]},"metadata":{},"execution_count":25}],"source":["# Convert a torch tensor to an numpy array\n","\n","z = y.numpy()\n","\n","z"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XwVxYVOAfcf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759276818,"user_tz":-300,"elapsed":6210,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"7ac9d041-5adf-46f5-cd12-b295b8e834e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m61.4/68.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# for save\n","\n","!pip install jovian --upgrade --quiet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dFjNH8W8gHJs"},"outputs":[],"source":["import jovian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lC7mT6jagO9g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277646,"user_tz":-300,"elapsed":94,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"7a48e15a-583c-4ee3-bb6d-2b839d9481e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[jovian] Detected Colab notebook...\u001b[0m\n","[jovian] jovian.commit() is no longer required on Google Colab. If you ran this notebook from Jovian, \n","then just save this file in Colab using Ctrl+S/Cmd+S and it will be updated on Jovian. \n","Also, you can also delete this cell, it's no longer necessary.\u001b[0m\n"]}],"source":["jovian.commit(project='01-pytorch-basics-live')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"egBdk0LvguwG"},"outputs":[],"source":["##########################################\n","######  Linear Regression and Gradient Decent ############\n","##########################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x3FSRyZo_jx8"},"outputs":[],"source":["###########Input (Tempreture , Rainfall , Humidity)\n","import numpy as np\n","inputs = np.array([[73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70]], dtype='float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RPF1q_6lAA6m"},"outputs":[],"source":["##########Target Variables (Apples , Oranges)\n","\n","targets = np.array([[56, 70],\n","                    [81, 101],\n","                    [119, 133],\n","                    [22, 37],\n","                    [103, 119]], dtype = 'float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QH0Bki1ZBjSH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277647,"user_tz":-300,"elapsed":87,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"f147d452-a0eb-46bb-aa0e-96659c9d83d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.]])\n","tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])\n"]}],"source":["########## Convert numpy arrays into tensor\n","import torch\n","inputs = torch.from_numpy(inputs)\n","targets = torch.from_numpy(targets)\n","\n","print(inputs)\n","print(targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cmbaUhxzCDD0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277648,"user_tz":-300,"elapsed":83,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"f2385101-1899-4819-bcc8-afbb8f801063"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.4203, -1.2439, -0.6284],\n","        [ 1.4117, -0.4268,  2.9631]], requires_grad=True)\n","tensor([-1.8221,  0.4758], requires_grad=True)\n"]}],"source":["##########  Weights and biases\n","\n","w = torch.randn(2, 3, requires_grad=True)\n","b = torch.randn(2, requires_grad=True)\n","\n","print(w)\n","print(b)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4qdqedcE3Pt"},"outputs":[],"source":["############ matrics multiplication & transport of weight matric using model method\n","\n","def model(x):\n","  return x @ w.t() + b\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVNKNStsNcmE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277649,"user_tz":-300,"elapsed":79,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"393d3961-855b-42ca-f3d4-b3c5d657eaff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.4203,  1.4117],\n","        [-1.2439, -0.4268],\n","        [-0.6284,  2.9631]], grad_fn=<TBackward0>)"]},"metadata":{},"execution_count":35}],"source":["w.t()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUJusp2ZQQeG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p36-SackNisa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277649,"user_tz":-300,"elapsed":75,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"97700f08-aea6-4c15-a196-b90986b4f602"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-215.8667,  202.3493],\n","        [-280.7504,  281.0230],\n","        [-328.5177,  237.9650],\n","        [-223.4320,  235.7524],\n","        [-263.2250,  264.3304]], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":36}],"source":["inputs @ w.t() +b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAMslLjpNxOZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277650,"user_tz":-300,"elapsed":72,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"3aeaf7d1-ef3c-438c-f400-34b2dbdffe97"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-215.8667,  202.3493],\n","        [-280.7504,  281.0230],\n","        [-328.5177,  237.9650],\n","        [-223.4320,  235.7524],\n","        [-263.2250,  264.3304]], grad_fn=<AddBackward0>)\n"]}],"source":["#################  Genrate Predictions   ##############\n","\n","preds = model(inputs)\n","print(preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cW9U_TveQeFZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277650,"user_tz":-300,"elapsed":68,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"e3d095a8-2c6e-4b0f-c687-12cc00e12ed5"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])\n"]}],"source":[" ############# Now compare with targets for the right predictions\n","\n"," print(targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZg2Fx8MRCTQ"},"outputs":[],"source":["############  Loss Function   #############\n","\n","### Before we improve our model, we need a way to evaluate how well our model\n","### is performing. we can compare the models predictions with the actual targets using the following method.\n","### 1. calculate the diffrence between the two matrics (preds and targets)\n","### 2. square all elements of the diffrence matrics to remove negative values\n","### 3. caculate the result of elements in the resulting matrics\n","### 4. the result is a single number known as the mean squared error (MSE)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3rxISjIVceK"},"outputs":[],"source":["### diffrence between actual and predicted values\n","diff = preds - targets\n","# diff * diff => remove negative values\n","# torch.sum(diff * diff)/diff.numel  => sum and average of the square values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0vDSrdRVmu8"},"outputs":[],"source":["# MSE LOSS\n","\n","def mse(t1, t2):\n","  diff = t1 - t2\n","  return torch.sum(diff * diff)/diff.numel()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IXoAGr9tXhNv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277651,"user_tz":-300,"elapsed":63,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"9faed97a-2dad-4a2a-c7f9-5d49cade047c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(72097.0234, grad_fn=<DivBackward0>)\n"]}],"source":["############ Compute Loss ##############\n","\n","loss = mse(preds , targets)\n","\n","print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdX5GwKnX1sM"},"outputs":[],"source":["###############  compute gradients\n","\n","loss.backward()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEJJ51uobFwJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277652,"user_tz":-300,"elapsed":60,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"3a7f5828-7b53-436d-c672-48b8bb4e8d4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.4203, -1.2439, -0.6284],\n","        [ 1.4117, -0.4268,  2.9631]], requires_grad=True)\n","tensor([[-28400.6367, -31145.5312, -19103.0117],\n","        [ 13095.2178,  12254.5615,   8165.4863]])\n"]}],"source":["############## Gradients for weights\n","\n","print(w)\n","print(w.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTv3TD0wbQ9R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277652,"user_tz":-300,"elapsed":57,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"16f72351-4b56-47bc-e707-73c6a42f9b09"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-1.8221,  0.4758], requires_grad=True)\n","tensor([-338.5583,  152.2840])\n"]}],"source":["############## Gradients for baises\n","\n","print(b)\n","print(b.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3I42zr18cWIf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277653,"user_tz":-300,"elapsed":54,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"bb5b63dc-2836-49e5-9423-9fcc3622b06a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([0., 0.])\n"]}],"source":["######### when one pass is complete then we have to clear weight and baises zero using .zero_() method\n","\n","w.grad.zero_()\n","b.grad.zero_()\n","print(w.grad)\n","print(b.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RQc3wzFQjbMN"},"outputs":[],"source":["#######   Adjest weights and biases using gadient descent (optimization technique)\n","\n","# 1. generate predictions\n","# 2. calculate the loss\n","# 3. compute gradients w.r.t the weights and biases\n","# 4. adjust the wieghts by subtracting a small quantity proportional to the gradient\n","# reset the gradients to zero\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fV6CClf5lPFG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277654,"user_tz":-300,"elapsed":51,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"bb8dfaf6-cd8b-4946-c72f-ab2ed1901e7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-215.8667,  202.3493],\n","        [-280.7504,  281.0230],\n","        [-328.5177,  237.9650],\n","        [-223.4320,  235.7524],\n","        [-263.2250,  264.3304]], grad_fn=<AddBackward0>)\n"]}],"source":["########## Generate Predictions\n","preds = model(inputs)\n","print(preds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-RsBw5P5oBB9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277654,"user_tz":-300,"elapsed":47,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"7b4b742b-a69d-471d-8495-d98686ba075f"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(72097.0234, grad_fn=<DivBackward0>)\n"]}],"source":["######### Calculate the loss\n","loss = mse(preds , targets)\n","print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C6Suct3dolKX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277654,"user_tz":-300,"elapsed":43,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"9deae723-3c7f-4aa5-d5b5-b0f22a772e8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-28400.6367, -31145.5312, -19103.0117],\n","        [ 13095.2178,  12254.5615,   8165.4863]])\n","tensor([-338.5583,  152.2840])\n"]}],"source":["#compute gradients\n","loss.backward()\n","print(w.grad)\n","print(b.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAvJvvrCouNj"},"outputs":[],"source":["####### Adjust Weights & reset gradients\n","with torch.no_grad():    # it means that should not track , calculate, or modify gradients while updating the weights and biases. we just want to use the gradints values.\n","   w -=  w.grad * 1e-5\n","   b -=  b.grad * 1e-5      # b = b-b.grad\n","   w.grad.zero_()\n","   b.grad.zero_()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDHe0cvjqQ9C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277655,"user_tz":-300,"elapsed":41,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"36eeee97-d005-441d-8f64-47c271028df9"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-1.1363, -0.9324, -0.4374],\n","        [ 1.2807, -0.5493,  2.8815]], requires_grad=True)\n","tensor([-1.8188,  0.4743], requires_grad=True)\n"]}],"source":["print(w)\n","print(b)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"81wu2AOzuZFD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277655,"user_tz":-300,"elapsed":38,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"57c36714-f9f8-452f-dc99-b8173db90cac"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(49060.7422, grad_fn=<DivBackward0>)\n"]}],"source":["#### claculate loss\n","preds = model(inputs)\n","loss = mse(preds, targets)\n","print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-p2M1HHbvCS8"},"outputs":[],"source":["#########  Train for 100 epochs  #########    to reduce the loss further , we can repeat the process of adjusting the weight and biasess using the gradients multiple times.\n","\n","########  Each itration is called epoch.  let's train the model for 100 epochs.\n","\n","for i in range(100):\n","  preds = model(inputs)\n","  loss = mse(preds, targets)\n","  loss.backward()\n","  with torch.no_grad():\n","    w -= w.grad * 1e-5\n","    b -= b.grad * 1e-5\n","    w.grad.zero_()\n","    b.grad.zero_()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0Gdr5rg0CRs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277656,"user_tz":-300,"elapsed":36,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"dba7c4d7-8e47-4f1f-9798-dd1afd8eea27"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(516.2106, grad_fn=<DivBackward0>)\n"]}],"source":["#### once again, let's verify that the loss is now lower:\n","\n","### calculate loss\n","\n","preds = model(inputs)\n","loss = mse(preds , targets)\n","\n","print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezoKov6r03GA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277656,"user_tz":-300,"elapsed":33,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"080d9b7e-b05b-4fb9-f104-793cb863b644"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 59.8973,  76.9731],\n","        [ 83.1687, 118.8061],\n","        [112.1075,  80.9995],\n","        [ 38.6272,  76.6721],\n","        [ 92.9987, 127.6374]], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":56}],"source":["#### Predictions\n","\n","preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqTVM6Vv12Ua","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277657,"user_tz":-300,"elapsed":32,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"38b48578-7ed6-4258-81a8-e48e45820b88"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.]])"]},"metadata":{},"execution_count":57}],"source":["#### Targets\n","\n","targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JcE1-5iG151t"},"outputs":[],"source":["################   linear regression using pytorch built-ins     ######################\n","\n","#  wh have linear regression & gradient descent model using some basic tensor operations. hoever, since this is a common pattern in deep learning, pytorch provides several buit-in\n","# functions and classes to make it easy to create and train models with just a few lines of code. lets begin by importing the torch.nn package from pytorch, which contains utiluty\n","# classes for building neural networks.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-VAenMrlB9ko"},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKCxkwhfCDzq"},"outputs":[],"source":["# input (temp, rainfall, humidity)\n","\n","inputs = np.array([[73, 67, 43],\n","                   [91, 88, 64],\n","                   [87, 134, 58],\n","                   [102, 43, 37],\n","                   [69, 96, 70],\n","                   [74, 66, 43],\n","                   [91, 87, 65],\n","                   [88, 134, 59],\n","                   [101, 44, 37],\n","                   [68, 96, 71],\n","                   [73, 66, 44],\n","                   [92, 87, 64],\n","                   [87, 135, 57],\n","                   [103, 43, 36],\n","                   [68, 97, 70]],dtype='float32')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwhsihWUDMxh"},"outputs":[],"source":["### Targets  (apples and orages)\n","\n","targets = np.array([[56, 70],\n","                    [81, 101],\n","                    [119, 133],\n","                    [22, 37],\n","                    [103, 119],\n","                    [57, 69],\n","                    [80, 102],\n","                    [118, 132],\n","                    [21, 38],\n","                    [104, 118],\n","                    [57, 69],\n","                    [82, 100],\n","                    [118, 134],\n","                    [20, 38],\n","                    [102, 120]], dtype = 'float32')\n","\n","inputs = torch.from_numpy(inputs)\n","targets = torch.from_numpy(targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpYc5I_QDeoL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277659,"user_tz":-300,"elapsed":30,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"971a28b3-b887-4419-d1bc-db63d8bf973b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.],\n","        [ 74.,  66.,  43.],\n","        [ 91.,  87.,  65.],\n","        [ 88., 134.,  59.],\n","        [101.,  44.,  37.],\n","        [ 68.,  96.,  71.],\n","        [ 73.,  66.,  44.],\n","        [ 92.,  87.,  64.],\n","        [ 87., 135.,  57.],\n","        [103.,  43.,  36.],\n","        [ 68.,  97.,  70.]])\n","tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.],\n","        [ 57.,  69.],\n","        [ 80., 102.],\n","        [118., 132.],\n","        [ 21.,  38.],\n","        [104., 118.],\n","        [ 57.,  69.],\n","        [ 82., 100.],\n","        [118., 134.],\n","        [ 20.,  38.],\n","        [102., 120.]])\n"]}],"source":["print(inputs)\n","\n","print(targets)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_5EpJrCERcD"},"outputs":[],"source":["#### Dataset and DataLoader\n","\n","### we will create a tensordataset, which allows access to rows from inputs and targets as tuples , and provides standard apis for working with many different types of datasets\n","### in pytorch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2hRTKbbFHcvK"},"outputs":[],"source":["#### import tensorDataset\n","\n","from torch.utils.data import TensorDataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qUtZrm2HD3r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759277660,"user_tz":-300,"elapsed":27,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"7a4dd910-e464-44fd-c52d-5864e34a76a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 73.,  67.,  43.],\n","         [ 91.,  88.,  64.],\n","         [ 87., 134.,  58.],\n","         [102.,  43.,  37.],\n","         [ 69.,  96.,  70.]]),\n"," tensor([[ 56.,  70.],\n","         [ 81., 101.],\n","         [119., 133.],\n","         [ 22.,  37.],\n","         [103., 119.]]))"]},"metadata":{},"execution_count":65}],"source":["### Define dataset\n","\n","train_ds = TensorDataset(inputs , targets)\n","train_ds[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"56DnJYFRHT3d"},"outputs":[],"source":["#########  Creating DataLoader  ############\n","\n","### we will also create a DataLoader, which can split the data into batches of a predefined size while training. it also provides other\n","#utilities like shuffling and random sampling of data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n-z3E6GKIX_p"},"outputs":[],"source":["###########  import DataLoader ################\n","\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1nVVbF5PIheT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278553,"user_tz":-300,"elapsed":120,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"175b75bc-febe-4009-9706-3e039cbd7126"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":68}],"source":["###  Define Data Loader\n","\n","batch_size = 5\n","train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n","len(train_dl)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rJUu2wVjrsGK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278553,"user_tz":-300,"elapsed":112,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"3f6ddad3-cd7a-4036-931b-cb460e28a7c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["[tensor([[103.,  43.,  36.],\n","        [ 91.,  87.,  65.],\n","        [ 68.,  97.,  70.],\n","        [ 87., 134.,  58.],\n","        [ 74.,  66.,  43.]]), tensor([[ 20.,  38.],\n","        [ 80., 102.],\n","        [102., 120.],\n","        [119., 133.],\n","        [ 57.,  69.]])]\n"]}],"source":["first_batch = next(iter(train_dl))\n","print(first_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6bcgmpAGI1D1"},"outputs":[],"source":["### we can use the data loader in a for loop. lets look at an example."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIxBUN4XJeEy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278554,"user_tz":-300,"elapsed":104,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"f7e54d15-b3da-42ab-8e9c-e629e806308c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 73.,  67.,  43.],\n","        [ 91.,  88.,  64.],\n","        [ 87., 134.,  58.],\n","        [102.,  43.,  37.],\n","        [ 69.,  96.,  70.],\n","        [ 74.,  66.,  43.],\n","        [ 91.,  87.,  65.],\n","        [ 88., 134.,  59.],\n","        [101.,  44.,  37.],\n","        [ 68.,  96.,  71.],\n","        [ 73.,  66.,  44.],\n","        [ 92.,  87.,  64.],\n","        [ 87., 135.,  57.],\n","        [103.,  43.,  36.],\n","        [ 68.,  97.,  70.]])"]},"metadata":{},"execution_count":71}],"source":["inputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2UWmiKjLJo_L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278555,"user_tz":-300,"elapsed":97,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"705ecfe0-a4e2-42fb-ee49-017f183a93bd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.],\n","        [ 57.,  69.],\n","        [ 80., 102.],\n","        [118., 132.],\n","        [ 21.,  38.],\n","        [104., 118.],\n","        [ 57.,  69.],\n","        [ 82., 100.],\n","        [118., 134.],\n","        [ 20.,  38.],\n","        [102., 120.]])"]},"metadata":{},"execution_count":72}],"source":["targets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8xItaElI7lS","executionInfo":{"status":"ok","timestamp":1691759278555,"user_tz":-300,"elapsed":88,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"2d8f003b-453a-49dd-bbeb-429e52197fb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 91.,  88.,  64.],\n","        [ 73.,  66.,  44.],\n","        [ 68.,  97.,  70.],\n","        [ 68.,  96.,  71.],\n","        [101.,  44.,  37.]])\n","tensor([[ 81., 101.],\n","        [ 57.,  69.],\n","        [102., 120.],\n","        [104., 118.],\n","        [ 21.,  38.]])\n"]}],"source":["for xb, yb  in train_dl:     ### xb = input_batches      yb= target_batches\n","  print(xb)\n","  print(yb)\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SymcN5mgJA_x"},"outputs":[],"source":["### nn.linear ####\n","\n","### instead of initializing the weights & biases manually, we can define the model using the nn.linear class from pytorch, which does it automatically."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y-ZmMISKLhL8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278556,"user_tz":-300,"elapsed":80,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"4f924c8b-fca4-470d-d0b6-4c77fff83eab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter containing:\n","tensor([[ 0.2457, -0.3096,  0.0206],\n","        [-0.3916, -0.4526, -0.4563]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.5277, -0.0889], requires_grad=True)\n"]}],"source":["# define model\n","\n","model = nn.Linear(3, 2)   ### 3 column 2 row for inputs &&&& the last 2 represents : 2 biases and also 3=inputs & 2=outputs\n","print(model.weight)\n","print(model.bias)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"avKSiDegLs4G"},"outputs":[],"source":["### pytorch models also have a helful .parameters method, which returns a list containing all the weights and bias matrices present in the model. For our linear regression\n","#### model, we have one weight matrix and one bias matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ET4YNiqBPRfg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278556,"user_tz":-300,"elapsed":71,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"013285d3-341b-4441-c100-9772003e6d9e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([[ 0.2457, -0.3096,  0.0206],\n","         [-0.3916, -0.4526, -0.4563]], requires_grad=True),\n"," Parameter containing:\n"," tensor([ 0.5277, -0.0889], requires_grad=True)]"]},"metadata":{},"execution_count":77}],"source":["#### Parameters   it means how many features are there in a model like weights and biases etc\n","\n","list(model.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptph1M2GPYvI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278557,"user_tz":-300,"elapsed":60,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"698850a7-dd5a-4000-fd3f-dafe1bfc46cd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  -1.3986,  -78.6224],\n","        [  -3.0468, -104.7586],\n","        [ -18.3952, -121.2714],\n","        [  13.0334,  -76.3808],\n","        [ -10.8052, -102.5008],\n","        [  -0.8433,  -78.5615],\n","        [  -2.7166, -104.7624],\n","        [ -18.1290, -122.1194],\n","        [  12.4781,  -76.4417],\n","        [ -11.0303, -102.5655],\n","        [  -1.0684,  -78.6261],\n","        [  -2.4915, -104.6977],\n","        [ -18.7254, -121.2677],\n","        [  13.2586,  -76.3161],\n","        [ -11.3605, -102.5618]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":78}],"source":["### Generate predictions\n","\n","preds = model(inputs)\n","preds\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yNSBEeC2PkpH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278557,"user_tz":-300,"elapsed":51,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"4f99a2b2-b3ee-496c-9077-4c6936d6540d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.],\n","        [ 57.,  69.],\n","        [ 80., 102.],\n","        [118., 132.],\n","        [ 21.,  38.],\n","        [104., 118.],\n","        [ 57.,  69.],\n","        [ 82., 100.],\n","        [118., 134.],\n","        [ 20.,  38.],\n","        [102., 120.]])"]},"metadata":{},"execution_count":79}],"source":["targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Qb5quiwPoRt"},"outputs":[],"source":["### Loss >>> instead of defining a loss funtion manually, we can use the built-in loss function mse_lose\n","\n","### import nn.functional\n","\n","\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7nJNV4RQFsz"},"outputs":[],"source":["### nn.functional package contains many usefull loss functions and seeral other utilities.\n","\n","\n","### Define Loss Function\n","\n","loss_fn = F.mse_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PHH1JFfLQcNr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278558,"user_tz":-300,"elapsed":42,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"5c028d28-17aa-4622-9bde-3bf49979bc2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(23323.1680, grad_fn=<MseLossBackward0>)\n"]}],"source":["### let's compute the loss for the current predictions of our model.\n","\n","\n","loss = loss_fn(model(inputs) , targets)\n","\n","print(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k9GK_vTMQv76"},"outputs":[],"source":["################## Optimization   ################\n","\n","##instead of manipulating the models weights and biases using gradients we can use the optimizer optim.SGD SGD is short for stochastic gradient descent,\n","# the term stochastic (randomly selected batches) indicates that samples are selected in random batches instead of as a single group.\n","\n","\n","\n","### Define Optimizer\n","\n","opt = torch.optim.SGD(model.parameters(), lr= 1e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YgtW7oUiTw_t"},"outputs":[],"source":["##############################    All steps in one function  #####################\n","\n","### the only change is that we will work batches of data instead of processing the entire training data in every iteration. let's define a utility function fit\n","###that trains the model for a given number of epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3TPjfLGZFSO"},"outputs":[],"source":["############ Utility function to train the model  ##############33\n","\n","def fit(num_epochs, model, loss_fn, opt, train_dl):\n","\n","\n","  # repeat for given number of epochs\n","  for epoch in range(num_epochs):\n","\n","    #Train with batches of data\n","    for xb, yb in train_dl:\n","\n","      # 1. generate predictions\n","      pred = model(xb)\n","\n","      # 2. calculate loss\n","      loss = loss_fn(pred, yb)\n","\n","      # 3. compute gradients\n","      loss.backward()\n","\n","      # 4. update parameters using gradients\n","      opt.step()\n","\n","      # 5. reset the gradients to zero\n","      opt.zero_grad()\n","\n","\n","        # print the progress\n","    if (epoch+1) % 10 == 0:\n","      print('Epoch [{}/{}], LOSS: {:.4f}'.format(epoch+1, num_epochs, loss.item()))  ### that prints the loss from the last batch of data for every 10th epoch to track training progress."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQV2rwyzc9YE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759582380,"user_tz":-300,"elapsed":8,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"b0da3557-f71e-4f92-f61a-36463bda16f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/100], LOSS: 14.5961\n","Epoch [20/100], LOSS: 9.2249\n","Epoch [30/100], LOSS: 10.2218\n","Epoch [40/100], LOSS: 4.7474\n","Epoch [50/100], LOSS: 7.7360\n","Epoch [60/100], LOSS: 6.9036\n","Epoch [70/100], LOSS: 12.6845\n","Epoch [80/100], LOSS: 6.8621\n","Epoch [90/100], LOSS: 6.8979\n","Epoch [100/100], LOSS: 3.6843\n"]}],"source":["####  pass the parameters ##########\n","\n","fit(100 , model, loss_fn, opt, train_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBDYKEjWdxXH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278560,"user_tz":-300,"elapsed":28,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"ecce3758-309f-43cd-ef6a-e2f95f69b35d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 58.8491,  71.8574],\n","        [ 81.6125,  97.6322],\n","        [117.0833, 137.7507],\n","        [ 30.3860,  45.3866],\n","        [ 95.5789, 108.9246],\n","        [ 57.8221,  70.8652],\n","        [ 81.2570,  97.0962],\n","        [117.3246, 138.0522],\n","        [ 31.4131,  46.3787],\n","        [ 96.2505, 109.3808],\n","        [ 58.4936,  71.3214],\n","        [ 80.5855,  96.6401],\n","        [117.4388, 138.2867],\n","        [ 29.7145,  44.9304],\n","        [ 96.6060, 109.9168]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":87}],"source":["#### enerate Predictions\n","\n","preds = model(inputs)\n","\n","preds"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QEejAkifVxo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278561,"user_tz":-300,"elapsed":25,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"dbe69af2-b7b5-4dbf-92c3-acd79b1a9afb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 56.,  70.],\n","        [ 81., 101.],\n","        [119., 133.],\n","        [ 22.,  37.],\n","        [103., 119.],\n","        [ 57.,  69.],\n","        [ 80., 102.],\n","        [118., 132.],\n","        [ 21.,  38.],\n","        [104., 118.],\n","        [ 57.,  69.],\n","        [ 82., 100.],\n","        [118., 134.],\n","        [ 20.,  38.],\n","        [102., 120.]])"]},"metadata":{},"execution_count":88}],"source":["### compare with targets\n","targets\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPab3dYofYiK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691759278561,"user_tz":-300,"elapsed":22,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"f1cf43fe-57cf-49b9-fc45-58350c66d65d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[12.5539, 16.0556]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":89}],"source":["model(torch.tensor([[37., 10, 26]]))   # test the model on zhob city"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dCzlD8DhRRA","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"error","timestamp":1691759279976,"user_tz":-300,"elapsed":1433,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"0287e2ff-50c3-46b3-bff2-f5104103b2fa"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-90-699ee8e1e090>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use detach() here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'extend'"]}],"source":["from sklearn.metrics import accuracy_score\n","preds.extend(preds.cpu().detach().numpy())  # Use detach() here\n","targets.extend(targets.numpy())\n","accuracy = accuracy_score(targets, preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cnt6niXd0vmo"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}