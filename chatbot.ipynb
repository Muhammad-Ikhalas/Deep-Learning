{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"EfpWddG0QMS7","colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"status":"error","timestamp":1704280352494,"user_tz":-300,"elapsed":1349,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"f1af7d49-4815-4f5e-bceb-df476136c07e"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-50cc6ce5a23c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n"]},{"cell_type":"code","source":["import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"TFGrIFpS2W9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.core.display import JSON\n","file_path = '/content/drive/MyDrive/Chatbot/intents.json'\n","#file_path = 'intents.json'\n","\n","\n","with open(file_path, 'r') as file:\n","    content = json.load(file)\n","    print(content)\n"],"metadata":{"id":"-ov867OcUsMH","executionInfo":{"status":"ok","timestamp":1693556663090,"user_tz":-300,"elapsed":20,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4697539e-62c5-41e2-e249-609a4aa7b49b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you', 'Hi there, how can I help you']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later thanks for visiting', 'Have a nice day', 'By! Come back again soon']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", 'Thanks a lot!'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'Items', 'patterns': ['Which items do you have?', 'What Kinds of items are there?', 'What do you sell?'], 'responses': ['we seel coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with paypal?', 'Are you cash only?'], 'responses': ['We accept VISA , Mastercard and Paypal', 'We accept most major credit cards, and paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}]}\n"]}]},{"cell_type":"code","source":["import nltk\n","\n","nltk.download('punkt')"],"metadata":{"id":"B4GTmaA0WmWV","executionInfo":{"status":"ok","timestamp":1693556664865,"user_tz":-300,"elapsed":1788,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bcc5e5be-98e6-40b2-de82-d5b21ca1a7ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["from nltk.stem.porter import PorterStemmer\n","\n","stemmer = PorterStemmer()\n","\n","\n"],"metadata":{"id":"uNxc0-kZXB0O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize(sentence):\n","  return nltk.word_tokenize(sentence)\n","\n","\n","\n","a = \"a quick brown fox jumps over the lazy dog\"\n","print(a)\n","a = tokenize(a)\n","print(a)"],"metadata":{"id":"ZKSL5f7HXhuK","executionInfo":{"status":"ok","timestamp":1693556664867,"user_tz":-300,"elapsed":28,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ccc49749-0d46-40a0-f275-b3be0dc68609"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["a quick brown fox jumps over the lazy dog\n","['a', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n"]}]},{"cell_type":"code","source":["def stem(word):\n","  return stemmer.stem(word.lower())\n","\n","words = [\"Organize\", \"organizes\", \"ORGanizing\"]\n","stemmed_words = [stem(w) for w in words]\n","print(stemmed_words)"],"metadata":{"id":"AIhNpNLXX20k","executionInfo":{"status":"ok","timestamp":1693556664867,"user_tz":-300,"elapsed":22,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"535bf2a0-0534-4f03-a345-2e9b9a537097"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['organ', 'organ', 'organ']\n"]}]},{"cell_type":"code","source":["def bag_of_words(tokenized_sentence, all_words):\n","  \"\"\"\n","  sentence = [\"hello\", \"how\", \"are\", \"you\"]\n","  words =    [\"hi\", \"hello\", \"I\", \"you\", \"bye\",\"thank\", \"cool\"]\n","  bag =      [ 0,    1,   0,   1,   0,   0,   0]\n","  \"\"\"\n","\n","  tokenized_sentence = [stem(w) for w in tokenized_sentence]\n","\n","  bag = np.zeros(len(all_words), dtype=np.float32)\n","  for idx , w in enumerate(all_words):\n","    if w in tokenized_sentence:\n","      bag[idx]=1.0\n","\n","  return bag\n","\n","\n","\n"],"metadata":{"id":"R_-nA39EYgyu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","all_words = []\n","tags = []\n","xy = []\n"],"metadata":{"id":"g5ABijLbYrp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for intent in content['intents']:\n","  tag = intent['tag']\n","  tags.append(tag)\n","  for pattern in intent['patterns']:\n","    w = tokenize(pattern)\n","    all_words.extend(w)\n","    xy.append((w, tag))\n","\n","\n","ignore_words = ['?', '!', '.']\n","all_words = [stem(w) for w in all_words if w not in ignore_words]\n","all_words = sorted(set(all_words))\n","tags = sorted(set(tags))\n","print(all_words)\n","print(tags)\n"],"metadata":{"id":"r4FBMBJKblLq","executionInfo":{"status":"ok","timestamp":1693556664869,"user_tz":-300,"elapsed":20,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6cdf859b-a9f8-4d2e-f724-e6807526d519"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n","['Items', 'delivery', 'funny', 'goodbye', 'greeting', 'payments', 'thanks']\n"]}]},{"cell_type":"code","source":["X_train = []\n","y_train = []\n","\n","\n","for (pattern_sentence, tag) in xy:\n","  bag = bag_of_words(pattern_sentence, all_words)\n","  X_train.append(bag)\n","\n","  label = tags.index(tag)\n","  y_train.append(label)\n","\n","X_train= np.array(X_train)\n","y_train= np.array(y_train)\n","\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","\n","\n","\n"],"metadata":{"id":"_2Db_A7UcNx1","executionInfo":{"status":"ok","timestamp":1693556664869,"user_tz":-300,"elapsed":18,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"188d9ec9-255e-4f3a-bb15-9ba43334380a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(26, 54)\n","(26,)\n"]}]},{"cell_type":"code","source":["class ChatDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.n_samples = len(X)\n","        self.x_data = X\n","        self.y_data = y\n","\n","    def __getitem__(self, index):\n","        x = self.x_data[index]\n","        y = self.y_data[index]\n","        return x, y\n","\n","    def __len__(self):\n","        return self.n_samples"],"metadata":{"id":"vFQ-AyeHx5u1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = ChatDataset(X_train, y_train)"],"metadata":{"id":"QlLeFzPk1xSG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# hyperparameters\n","batch_size = 8\n","learning_rate = 0.001\n","num_epochs = 1000\n","hidden_size = 8\n","output_size = len(tags)\n","input_size = len(X_train[0])\n","print(input_size, len(all_words))\n","print(output_size, tags)\n"],"metadata":{"id":"qgJKdBiQ11jm","executionInfo":{"status":"ok","timestamp":1693556664871,"user_tz":-300,"elapsed":17,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1545297-f0b2-4322-bdda-777ba5a33dd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["54 54\n","7 ['Items', 'delivery', 'funny', 'goodbye', 'greeting', 'payments', 'thanks']\n"]}]},{"cell_type":"code","source":["train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","\n"],"metadata":{"id":"LSkitLgZ6ivN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Train Model"],"metadata":{"id":"__BJMkmD3CBy"}},{"cell_type":"code","source":["class NeuralNet(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_classes):\n","    super(NeuralNet, self).__init__()\n","    self.l1 = nn.Linear(input_size, hidden_size)\n","    self.l2 = nn.Linear(hidden_size, hidden_size)\n","    self.l3 = nn.Linear(hidden_size, num_classes)\n","    self.relu = nn.ReLU()\n","\n","  def forward(self, x):\n","    out = self.l1(x)\n","    out = self.relu(out)\n","    out = self.l2(out)\n","    out = self.relu(out)\n","    out = self.l3(out)\n","    # no activation and no softmax\n","    return out\n","\n","\n","\n"],"metadata":{"id":"NesoM-Ix3Agl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENKYjPJm6-jO","executionInfo":{"status":"ok","timestamp":1693556664872,"user_tz":-300,"elapsed":15,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"9226826a-8363-4bcc-d19f-5867dbe88bf9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["model = NeuralNet(input_size, hidden_size, output_size).to(device)"],"metadata":{"id":"Uyqf1ksI5A9y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","###Loss and optimizer"],"metadata":{"id":"u7XUXRTl8gm5"}},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"metadata":{"id":"vTj3r0zC61bH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epochs):\n","  for (words, labels) in train_loader:\n","    words = words.to(device)\n","    labels = labels.to(device)\n","\n","\n","    #forward\n","    outputs = model(words)\n","    Loss = loss(outputs, labels)\n","\n","\n","    #backward and optimizer steps\n","    optimizer.zero_grad()\n","    Loss.backward()\n","    optimizer.step()\n","\n","  if (epoch +1) % 100==0:\n","    print(f'epoch{epoch+1}/{num_epochs}, Loss = {Loss.item():.4f}')\n","\n","\n","print(f'final loss,loss = {Loss.item():.4f}')\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_vKpyR582GQ","executionInfo":{"status":"ok","timestamp":1693556792239,"user_tz":-300,"elapsed":121578,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"66470508-4c09-4be5-b5e7-1450f79f35b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch100/1000, Loss = 1.1398\n","epoch200/1000, Loss = 0.1174\n","epoch300/1000, Loss = 0.1087\n","epoch400/1000, Loss = 0.0210\n","epoch500/1000, Loss = 0.0127\n","epoch600/1000, Loss = 0.0056\n","epoch700/1000, Loss = 0.0007\n","epoch800/1000, Loss = 0.0029\n","epoch900/1000, Loss = 0.0008\n","epoch1000/1000, Loss = 0.0014\n","final loss,loss = 0.0014\n"]}]},{"cell_type":"code","source":["data = {\n","    \"model_state\": model.state_dict(),\n","    \"input_size\": input_size,\n","    \"output_size\": output_size,\n","    \"hidden_size\": hidden_size,\n","    \"all_words\": all_words,\n","    \"tags\": tags\n","}\n","FILE = \"/content/drive/MyDrive/Parameter.pth\"\n","torch.save(data, FILE)\n","\n","print(f'training complete. file saved to {FILE}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L_wphVg9fYfC","executionInfo":{"status":"ok","timestamp":1693556792240,"user_tz":-300,"elapsed":9,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"5d5681b4-354a-4793-af57-1a3a9e171093"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training complete. file saved to /content/drive/MyDrive/Parameter.pth\n"]}]},{"cell_type":"code","source":["import random\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","data = torch.load(FILE)\n","print(data)\n","\n","input_size = data[\"input_size\"]\n","hidden_size = data[\"hidden_size\"]\n","output_size = data[\"output_size\"]\n","all_words = data[\"all_words\"]\n","tags = data[\"tags\"]\n","model_state = data[\"model_state\"]\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","model.load_state_dict(model_state)\n","model.eval()\n"],"metadata":{"id":"f8waAUO-9ZK0","executionInfo":{"status":"ok","timestamp":1693556793324,"user_tz":-300,"elapsed":1089,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"669b5cd8-18b3-47fd-bbb1-46101d37bf3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'model_state': OrderedDict([('l1.weight', tensor([[-0.1238, -0.4205,  0.3105,  0.3708,  0.8344, -0.5801,  0.3289,  0.5599,\n","          0.1140,  0.4738,  0.7218, -0.3037,  0.3585, -0.4746, -0.1890, -0.3160,\n","          0.6085, -0.6248,  0.4762,  0.9070, -0.2926,  0.7618,  0.9104,  0.6113,\n","          0.0721,  0.5736,  0.6261, -0.4836,  0.4416, -0.3919, -0.4843, -0.4351,\n","         -0.1261,  0.3081, -0.2049, -0.1186,  0.3496, -0.0582,  0.3649,  0.3002,\n","         -0.3631,  0.6111, -0.2527, -0.0613, -0.0293, -0.1765, -0.6308, -0.1546,\n","          0.6526,  0.7267, -0.3222,  0.4561,  0.3964,  0.4548],\n","        [ 0.0402, -0.5218, -0.1987,  0.4150,  0.2692,  0.8821, -0.0062,  0.0037,\n","         -0.4128, -0.0248,  0.4037, -0.2825,  0.1063, -0.3576, -0.1598, -0.2301,\n","          0.3162,  0.8129,  0.4564,  0.4607, -0.0991,  0.5842,  0.5228,  0.2306,\n","         -0.2189,  0.2398,  0.5967, -0.3012,  0.2507, -0.5095,  0.4510, -0.4488,\n","          0.0853, -0.2885, -0.3329, -0.1869,  0.2202, -0.2615, -0.0374, -0.0581,\n","          0.5573,  0.6139, -0.2828, -0.2150, -0.1728, -0.3221, -0.4212, -0.0536,\n","          0.4532,  0.7663, -0.2179,  0.6137,  0.1419,  0.2180],\n","        [ 0.1693,  0.4015,  0.1389,  0.1921,  0.1380,  0.9196,  0.4413,  0.3238,\n","          0.3558,  0.3831,  0.1755, -0.4275,  0.1272, -0.3651, -0.1045, -0.2100,\n","          0.2161,  0.6737,  0.3030,  0.1916,  0.0391,  0.0899,  0.1799, -0.4215,\n","          0.0318,  0.0148,  0.5053,  0.1039,  0.4157, -0.0784,  0.6995, -0.2049,\n","          0.3470,  0.2675,  0.1944, -0.2844,  0.2934,  0.1340,  0.5536,  0.4058,\n","          0.7101,  0.3428, -0.3583, -0.0410,  0.2325,  0.2763,  0.0793,  0.1074,\n","          0.1973,  0.5390, -0.3273,  0.5376,  0.4325,  0.3023],\n","        [ 0.1903,  0.4776,  0.4738,  0.0663,  0.1925, -0.3927,  0.4832,  0.3704,\n","          0.5655,  0.4259, -0.1341,  0.6887,  0.3833,  0.8216,  0.6526,  0.5913,\n","         -0.0345, -0.3927, -0.4359, -0.2527,  0.1017, -0.2262, -0.2346, -0.2891,\n","          0.7806, -0.0362, -0.4280,  0.8824, -0.1095,  0.7133, -0.4361,  0.6310,\n","         -0.3594,  0.4630,  0.6487,  0.7501, -0.1133,  0.5483,  0.3672,  0.5398,\n","         -0.4218, -0.6058,  0.5198,  0.6708,  0.8087,  0.7624,  0.3863,  0.2234,\n","         -0.0652, -0.6352,  0.5409, -0.3772,  0.3378,  0.4650],\n","        [ 0.0062,  0.5014,  0.4511, -0.2737, -0.0303,  0.4151,  0.3770,  0.3694,\n","          0.6384,  0.3752, -0.2210, -0.0408,  0.7860,  0.5168,  0.5755, -0.2644,\n","         -0.0524,  0.3010,  0.5971, -0.2730,  0.1176, -0.2731, -0.2730, -0.3679,\n","          0.4276, -0.2230,  0.6979,  0.7901,  0.4218,  0.5594, -0.0766,  0.3034,\n","         -0.1557,  0.4471,  0.6829, -0.1942,  0.5803,  0.4678,  0.3658,  0.3759,\n","         -0.1296,  0.5955,  0.0608,  0.6449,  0.7175,  0.6783, -0.6187, -0.0570,\n","          0.2239,  0.7510, -0.1128,  0.5012,  0.5127,  0.4179],\n","        [-0.1250,  0.0490, -0.0645, -0.0953, -0.0770, -0.0469, -0.0890,  0.0400,\n","         -0.0797,  0.0648,  0.0739, -0.0195, -0.0651, -0.1066,  0.0463,  0.0400,\n","          0.0263,  0.1117,  0.0039,  0.0990, -0.0670,  0.0805, -0.0398, -0.0140,\n","          0.0464,  0.0547,  0.0999,  0.0175, -0.1134, -0.0945, -0.1031,  0.0190,\n","         -0.0666, -0.0255, -0.0526, -0.0618, -0.1033,  0.0241,  0.0612,  0.0562,\n","          0.0830,  0.1348,  0.0068,  0.0628,  0.0484, -0.0332, -0.1095,  0.1249,\n","          0.0111, -0.1098,  0.1001, -0.0580, -0.0104,  0.0252],\n","        [ 0.8740,  0.5125, -0.0227, -0.1413, -0.1462,  0.5289, -0.0658, -0.1245,\n","          0.0873, -0.1411, -0.1245,  0.8349,  0.1196,  0.7384,  0.0633,  0.5535,\n","         -0.1984,  0.4483, -0.4999, -0.4395,  0.8057, -0.4756, -0.4457,  0.6503,\n","          0.4430, -0.0690, -0.4127,  0.4042, -0.0437,  0.4114,  0.3503,  0.8952,\n","          0.4942,  0.0910,  0.3432,  0.6861, -0.0365,  0.1808,  0.0329, -0.0487,\n","          0.4784, -0.7770,  0.6903,  0.2502,  0.7949,  0.3247,  1.4043,  0.6663,\n","         -0.0263, -0.6187,  0.7017, -0.4833, -0.0756,  0.3054],\n","        [-0.0537,  0.3009,  0.1249, -0.2572, -0.0351,  0.8056,  0.3208,  0.2427,\n","          0.1984,  0.3445, -0.1350, -0.1427,  0.5489, -0.0931,  0.2318, -0.3473,\n","         -0.3039,  0.8950,  0.5761, -0.4531, -0.2765, -0.4531, -0.4531, -0.3140,\n","          0.1865, -0.3118,  0.7217,  0.3514,  0.5344,  0.1834,  0.5769, -0.0385,\n","         -0.1183,  0.2576,  0.4934, -0.3842,  0.3514,  0.3907,  0.1990,  0.3620,\n","          0.4796,  0.6469, -0.1090,  0.2900,  0.0411,  0.4578, -0.6616, -0.1250,\n","          0.1862,  0.5665, -0.3143,  0.5639,  0.2271,  0.2086]],\n","       device='cuda:0')), ('l1.bias', tensor([ 0.6308,  1.0297,  1.1171,  0.3927,  0.2730, -0.1433,  0.9709,  0.4532],\n","       device='cuda:0')), ('l2.weight', tensor([[-0.0341, -0.3460, -0.0831, -0.0178, -0.2593, -0.2416, -0.2702,  0.0115],\n","        [ 1.5426,  0.5601,  0.2866, -0.3238,  0.5476, -0.2038, -0.7974,  0.2119],\n","        [-0.7699, -0.7310,  0.3451,  1.3656,  1.0354,  0.2331,  1.6585, -0.2298],\n","        [ 1.0777,  1.2891,  1.2191, -0.3486, -0.6494, -0.2368,  0.2218,  0.1410],\n","        [ 0.0115,  0.2719,  0.2527, -0.9554,  0.6617, -0.0812, -0.5263,  1.0910],\n","        [-0.1954,  0.1125,  0.0564, -0.2571,  0.2148,  0.3314,  0.0211, -0.3220],\n","        [-0.6252,  0.6691,  0.6508, -0.8613, -0.2561,  0.0568,  0.5966,  0.6127],\n","        [-0.3523, -0.0250,  0.7829,  0.4716,  1.3962,  0.0801, -0.5273,  1.4652]],\n","       device='cuda:0')), ('l2.bias', tensor([-0.2040,  0.1850,  0.9360,  0.8727, -0.3401, -0.2687,  0.0740, -0.2315],\n","       device='cuda:0')), ('l3.weight', tensor([[ 0.1455,  0.3367, -1.2663, -0.0173,  0.6588, -0.3384, -0.4169,  0.3292],\n","        [ 0.3448, -0.9523,  0.8467, -1.4712, -0.5103, -0.2942, -1.6279, -0.8356],\n","        [ 0.0334, -1.6263,  0.2940, -1.2849, -0.8820,  0.2920, -1.0238,  0.9377],\n","        [-0.3234, -0.7154, -0.8058,  0.2989,  0.1125,  0.0894,  1.0049,  0.0879],\n","        [-0.2787,  0.5835, -1.1611,  1.0278, -0.8679, -0.3378, -0.4020, -1.5527],\n","        [-0.0561, -0.1123, -0.1717,  0.0976,  0.1109,  0.1315, -1.7611,  0.5353],\n","        [-0.1462, -1.5800,  0.3619,  0.3340, -1.0867, -0.0158,  0.3832, -1.5964]],\n","       device='cuda:0')), ('l3.bias', tensor([-0.6127,  0.1696, -0.4683,  0.0587,  0.3450, -0.0914,  0.3887],\n","       device='cuda:0'))]), 'input_size': 54, 'output_size': 7, 'hidden_size': 8, 'all_words': [\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you'], 'tags': ['Items', 'delivery', 'funny', 'goodbye', 'greeting', 'payments', 'thanks']}\n"]},{"output_type":"execute_result","data":{"text/plain":["NeuralNet(\n","  (l1): Linear(in_features=54, out_features=8, bias=True)\n","  (l2): Linear(in_features=8, out_features=8, bias=True)\n","  (l3): Linear(in_features=8, out_features=7, bias=True)\n","  (relu): ReLU()\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["bot_name = \"Shara\"\n","print(\"Let's chat! type 'quit' to exit\")\n","while True:\n","  sentence = input('You: ')\n","  if sentence == \"quit\":\n","    break\n","  sentence = tokenize(sentence)\n","  X = bag_of_words(sentence, all_words)\n","  X = X.reshape(1, X.shape[0])\n","  X = torch.from_numpy(X).to(device)  # Assuming 'device' is the desired device (CPU or GPU)\n","\n","  output = model(X)\n","  _, predicted = torch.max(output, dim=1)\n","  tag = tags[predicted.item()]\n","\n","  probs = torch.softmax(output, dim=1)\n","  prob = probs[0] [predicted.item()]\n","\n","  if prob.item() > 0.75:\n","    for intent in content[\"intents\"]:\n","      if tag == intent[\"tag\"]:\n","         print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n","\n","  else:\n","    print(f\"{bot_name}: I do not understand...\")\n","\n","\n","\n"],"metadata":{"id":"try0fAZ__6HI","executionInfo":{"status":"ok","timestamp":1693390405138,"user_tz":-300,"elapsed":22869,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6b7ab71-8f40-4d87-b0c5-2f553bdecad3"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Let's chat! type 'quit' to exit\n","You: hi\n","Shara: Hi there, what can I do for you\n","You: what's up\n","Shara: I do not understand...\n","You: quit\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# Assuming 'model' is your PyTorch model\n","#model_path = '/content/drive/MyDrive/data.pth'  # Replace with your desired file path and name\n","\n","# Save the PyTorch model to Google Drive\n","torch.save(model.state_dict(), \"FILE\")\n"],"metadata":{"id":"aRNG4nD9hWl5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lo0QHPOPHah7"},"execution_count":null,"outputs":[]}]}