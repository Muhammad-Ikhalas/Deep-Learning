{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1522,"status":"ok","timestamp":1699084897367,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"SW5AfFrY8lTn","outputId":"e7186213-59f7-44b7-d74e-466804269a19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'smunet'...\n","remote: Enumerating objects: 41, done.\u001b[K\n","remote: Counting objects: 100% (41/41), done.\u001b[K\n","remote: Compressing objects: 100% (41/41), done.\u001b[K\n","remote: Total 41 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n","Receiving objects: 100% (41/41), 650.61 KiB | 14.46 MiB/s, done.\n","Resolving deltas: 100% (9/9), done.\n"]}],"source":["!git clone \"https://github.com/rezazad68/smunet.git\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5234,"status":"ok","timestamp":1699084902598,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"ibz5oJYW9Ry8"},"outputs":[],"source":["!pip install opendatasets --upgrade --quiet"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":226125,"status":"ok","timestamp":1699085128718,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"hveTMqRc9C19","outputId":"4df9afbf-4ad0-4d33-db5c-d3fe3fc3101c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n","Your Kaggle username: iamsanaullah\n","Your Kaggle Key: ··········\n","Downloading brats2018.zip to ./brats2018\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3.18G/3.18G [00:35<00:00, 95.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["# get the data from\n","import opendatasets as od\n","dataset_url = 'https://www.kaggle.com/datasets/sanglequang/brats2018'\n","od.download(dataset_url)\n","\n","# https://www.kaggle.com/datasets/sanglequang/brats2018\n","# https://www.kaggle.com/datasets/awsaf49/brats20-dataset-training-validation\n"]},{"cell_type":"markdown","metadata":{"id":"cak5BdqrESzc"},"source":["data.py"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4708,"status":"ok","timestamp":1699085133424,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"t80S3EgG-hCK"},"outputs":[],"source":["#!/usr/bin/env python3\n","# encoding: utf-8\n","# Code modified from https://github.com/Wangyixinxin/ACN\n","import glob\n","import os\n","import numpy as np\n","import nibabel as nib\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import random\n","\n","class Brats2018(Dataset):\n","\n","    def __init__(self, patients_dir, crop_size, modes, train=True, normalization = True):\n","        self.patients_dir = patients_dir\n","        self.modes = modes\n","        self.train = train\n","        self.crop_size = crop_size\n","        self.normalization = normalization\n","\n","    def __len__(self):\n","        return len(self.patients_dir)\n","\n","    def __getitem__(self, index):\n","        patient_dir = self.patients_dir[index]\n","        volumes = []\n","        modes = list(self.modes) + ['seg']\n","        for mode in modes:\n","            patient_id = os.path.split(patient_dir)[-1]\n","            volume_path = os.path.join(patient_dir, patient_id + \"_\" + mode + '.nii')\n","            volume = nib.load(volume_path).get_data()\n","            if not mode == \"seg\" and self.normalization:\n","                volume = self.normlize(volume)  # [0, 1.0]\n","            volumes.append(volume)                  # [h, w, d]\n","        seg_volume = volumes[-1]\n","        volumes = volumes[:-1]\n","        volume, seg_volume = self.aug_sample(volumes, seg_volume)\n","        ed_volume = (seg_volume == 2) # peritumoral edema ED\n","        net_volume = (seg_volume == 1) # enhancing tumor core NET\n","        et_volume = (seg_volume == 4) # enhancing tumor ET\n","        bg_volume = (seg_volume == 0)\n","\n","        seg_volume = [ed_volume, net_volume, et_volume, bg_volume]\n","        seg_volume = np.concatenate(seg_volume, axis=0).astype(\"float32\")\n","\n","        return (torch.tensor(volume.copy(), dtype=torch.float),\n","                torch.tensor(seg_volume.copy(), dtype=torch.float))\n","\n","\n","    def aug_sample(self, volumes, mask):\n","        \"\"\"\n","            Args:\n","                volumes: list of array, [h, w, d]\n","                mask: array [h, w, d], segmentation volume\n","            Ret: x, y: [channel, h, w, d]\n","\n","        \"\"\"\n","        x = np.stack(volumes, axis=0)       # [N, H, W, D]\n","        y = np.expand_dims(mask, axis=0)    # [channel, h, w, d]\n","\n","        if self.train:\n","            # crop volume\n","            x, y = self.random_crop(x, y)\n","            if random.random() < 0.5:\n","                x = np.flip(x, axis=1)\n","                y = np.flip(y, axis=1)\n","            if random.random() < 0.5:\n","                x = np.flip(x, axis=2)\n","                y = np.flip(y, axis=2)\n","            if random.random() < 0.5:\n","                x = np.flip(x, axis=3)\n","                y = np.flip(y, axis=3)\n","        else:\n","            x, y = self.center_crop(x, y)\n","\n","        return x, y\n","\n","    def random_crop(self, x, y):\n","        \"\"\"\n","        Args:\n","            x: 4d array, [channel, h, w, d]\n","        \"\"\"\n","        crop_size = self.crop_size\n","        height, width, depth = x.shape[-3:]\n","        sx = random.randint(0, height - crop_size[0] - 1)\n","        sy = random.randint(0, width - crop_size[1] - 1)\n","        sz = random.randint(0, depth - crop_size[2] - 1)\n","        crop_volume = x[:, sx:sx + crop_size[0], sy:sy + crop_size[1], sz:sz + crop_size[2]]\n","        crop_seg = y[:, sx:sx + crop_size[0], sy:sy + crop_size[1], sz:sz + crop_size[2]]\n","\n","        return crop_volume, crop_seg\n","\n","    def center_crop(self, x, y):\n","        crop_size = self.crop_size\n","        height, width, depth = x.shape[-3:]\n","        sx = (height - crop_size[0] - 1) // 2\n","        sy = (width - crop_size[1] - 1) // 2\n","        sz = (depth - crop_size[2] - 1) // 2\n","        crop_volume = x[:, sx:sx + crop_size[0], sy:sy + crop_size[1], sz:sz + crop_size[2]]\n","        crop_seg = y[:, sx:sx + crop_size[0], sy:sy + crop_size[1], sz:sz + crop_size[2]]\n","\n","        return crop_volume, crop_seg\n","\n","    def normlize(self, x):\n","        return (x - x.min()) / (x.max() - x.min())\n","\n","\n","    def normlize_brain(self, x, epsilon=1e-8):\n","        average        = x[np.nonzero(x)].mean()\n","        std            = x[np.nonzero(x)].std() + epsilon\n","        mask           = x>0\n","        sub_mean       = np.where(mask, x-average, x)\n","        x_normalized   = np.where(mask, sub_mean/std, x)\n","        return x_normalized\n","\n","def split_dataset(data_root, test_p):\n","    patients_dir = glob.glob(os.path.join(data_root, \"*GG\", \"Brats18*\"))\n","    patients_dir.sort()\n","    N = int(len(patients_dir)*test_p)\n","    train_patients_list =  patients_dir[N:]\n","    val_patients_list   =  patients_dir[:N]\n","\n","    return train_patients_list, val_patients_list\n","\n","def make_data_loaders(config):\n","    train_list, val_list = split_dataset(config['path_to_data'], float(config['test_p']))\n","    crop_size = np.zeros((3))\n","    crop_size[0] = config['inputshape'][0]\n","    crop_size[1] = config['inputshape'][1]\n","    crop_size[2] = config['inputshape'][2]\n","    crop_size    = crop_size.astype(np.uint16)\n","    crop_size    = (160, 192, 128)\n","    train_ds = Brats2018(train_list, crop_size=crop_size, modes=config['modalities'], train=True)\n","    val_ds = Brats2018(val_list,     crop_size=crop_size, modes=config['modalities'], train=False)\n","    loaders = {}\n","    loaders['train'] = DataLoader(train_ds, batch_size=int(config['batch_size_tr']),\n","                                  num_workers=4,\n","                                  pin_memory=True,\n","                                  shuffle=True)\n","    loaders['eval'] = DataLoader(val_ds, batch_size=int(config['batch_size_va']),\n","                                  num_workers=4,\n","                                  pin_memory=True,\n","                                  shuffle=False)\n","    return loaders"]},{"cell_type":"markdown","metadata":{"id":"ROO84WguEbt2"},"source":["models => unet.py"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1699085135058,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"FYJUtTwqFLf6"},"outputs":[],"source":["#!/usr/bin/env python3\n","# encoding: utf-8\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BasicBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, n_groups=8):\n","        super(BasicBlock, self).__init__()\n","        self.gn1 = nn.GroupNorm(n_groups, in_channels)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n","        self.gn2 = nn.GroupNorm(n_groups, in_channels)\n","        self.relu2 = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n","\n","    def forward(self, x):\n","        residul = x\n","        x = self.relu1(self.gn1(x))\n","        x = self.conv1(x)\n","\n","        x = self.relu2(self.gn2(x))\n","        x = self.conv2(x)\n","        x = x + residul\n","\n","        return x\n","\n","class UNet3D(nn.Module):\n","    \"\"\"3d unet\n","    Ref:\n","        3D MRI brain tumor segmentation using autoencoder regularization. Andriy Myronenko\n","    Args:\n","        input_shape: tuple, (height, width, depth)\n","    \"\"\"\n","\n","    def __init__(self, input_shape, in_channels=4, out_channels=3, init_channels=32, p=0.2):\n","        super(UNet3D, self).__init__()\n","        self.input_shape = input_shape\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.init_channels = init_channels\n","        self.make_encoder()\n","        self.make_decoder()\n","        self.dropout = nn.Dropout(p=p)\n","\n","    def make_encoder(self):\n","        init_channels = self.init_channels\n","        self.conv1a = nn.Conv3d(self.in_channels, init_channels, (3, 3, 3), padding=(1, 1, 1))\n","        self.conv1b = BasicBlock(init_channels, init_channels)  # 32\n","\n","        self.ds1 = nn.Conv3d(init_channels, init_channels * 2, (3, 3, 3), stride=(2, 2, 2),\n","                             padding=(1, 1, 1))  # down sampling and add channels\n","\n","        self.conv2a = BasicBlock(init_channels * 2, init_channels * 2)\n","        self.conv2b = BasicBlock(init_channels * 2, init_channels * 2)\n","\n","        self.ds2 = nn.Conv3d(init_channels * 2, init_channels * 4, (3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n","\n","        self.conv3a = BasicBlock(init_channels * 4, init_channels * 4)\n","        self.conv3b = BasicBlock(init_channels * 4, init_channels * 4)\n","\n","        self.ds3 = nn.Conv3d(init_channels * 4, init_channels * 8, (3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n","\n","        self.conv4a = BasicBlock(init_channels * 8, init_channels * 8)\n","        self.conv4b = BasicBlock(init_channels * 8, init_channels * 8)\n","        self.conv4c = BasicBlock(init_channels * 8, init_channels * 8)\n","        self.conv4d = BasicBlock(init_channels * 8, init_channels * 8)\n","\n","    def make_decoder(self):\n","        init_channels = self.init_channels\n","        self.up4conva = nn.Conv3d(init_channels * 8, init_channels * 4, (1, 1, 1))\n","        self.up4 = nn.Upsample(scale_factor=2)  # mode='bilinear'\n","        self.up4convb = BasicBlock(init_channels * 4, init_channels * 4)\n","\n","        self.up3conva = nn.Conv3d(init_channels * 4, init_channels * 2, (1, 1, 1))\n","        self.up3 = nn.Upsample(scale_factor=2)\n","        self.up3convb = BasicBlock(init_channels * 2, init_channels * 2)\n","\n","        self.up2conva = nn.Conv3d(init_channels * 2, init_channels, (1, 1, 1))\n","        self.up2 = nn.Upsample(scale_factor=2)\n","        self.up2convb = BasicBlock(init_channels, init_channels)\n","\n","        self.pool     = nn.MaxPool3d(kernel_size = 2)\n","        self.convc    = nn.Conv3d(init_channels * 20, init_channels * 8, (1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0))\n","        self.convco   = nn.Conv3d(init_channels * 16, init_channels * 8, (1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0))\n","        self.up1conv  = nn.Conv3d(init_channels, self.out_channels, (1, 1, 1))\n","\n","    def forward(self, x):\n","        c1 = self.conv1a(x)\n","        c1 = self.conv1b(c1)\n","        c1d = self.ds1(c1)\n","        #print(\"c1d shape:\", c1d.shape)\n","\n","        c2 = self.conv2a(c1d)\n","        c2 = self.conv2b(c2)\n","        c2d = self.ds2(c2)\n","        c2d_p = self.pool(c2d)\n","#         print(\"c2d shape:\", c2d_p.shape)\n","\n","        c3 = self.conv3a(c2d)\n","        c3 = self.conv3b(c3)\n","        c3d = self.ds3(c3)\n","#         print(\"c3d shape:\", c3d.shape)\n","\n","        c4 = self.conv4a(c3d)\n","        c4 = self.conv4b(c4)\n","        c4 = self.conv4c(c4)\n","        c4d = self.conv4d(c4) #[1, 128, 20, 24, 16]\n","#         print(\"c4d shape:\", c4d.shape)\n","\n","        style = self.convc(torch.cat([c2d_p, c3d, c4d], dim = 1))\n","        content = c4d\n","\n","        c4d = self.convco(torch.cat([style, content], dim = 1))\n","\n","        c4d = self.dropout(c4d)\n","\n","        u4 = self.up4conva(c4d)\n","        u4 = self.up4(u4)\n","        u4 = u4 + c3\n","        u4 = self.up4convb(u4)\n","\n","        u3 = self.up3conva(u4)\n","        u3 = self.up3(u3)\n","        u3 = u3 + c2\n","        u3 = self.up3convb(u3)\n","\n","        u2 = self.up2conva(u3)\n","        u2 = self.up2(u2)\n","        u2 = u2 + c1\n","        u2 = self.up2convb(u2)\n","\n","        uout = self.up1conv(u2)\n","        uout = F.sigmoid(uout)\n","\n","        return uout, style, content\n","\n","\n","class Unet_module(nn.Module):\n","\n","    def __init__(self, input_shape, in_channels=4, out_channels=3, init_channels=32, p=0.2):\n","        super(Unet_module, self).__init__()\n","        self.unet = UNet3D(input_shape, in_channels, out_channels, init_channels, p)\n","\n","    def forward(self, x):\n","        uout, style, content = self.unet(x)\n","        return uout, style, content"]},{"cell_type":"markdown","metadata":{"id":"XhwWkwbkFMhG"},"source":["model=> build.py"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699085135058,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"ZV-cWRE1FL2H"},"outputs":[],"source":["#!/usr/bin/env python3\n","# encoding: utf-8\n","\n","def build_model(inp_shape = (160, 192, 128), inp_dim1=4, inp_dim2 = 1):\n","    model_full    = Unet_module(inp_shape,\n","                      in_channels=inp_dim1,\n","                      out_channels=4,\n","                      init_channels=16,\n","                      p=0.2)\n","\n","    model_missing = Unet_module(inp_shape,\n","                      in_channels=inp_dim2,\n","                      out_channels=4,\n","                      init_channels=16,\n","                      p=0.2)\n","    return model_full, model_missing\n"]},{"cell_type":"markdown","metadata":{"id":"0IoBVZckFXRt"},"source":["model => discriminator.py"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699085135058,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"AePHjYsEFVgt"},"outputs":[],"source":["from torch import nn\n","\n","def get_style_discriminator(num_classes, ndf=64):\n","    return nn.Sequential(\n","        nn.Conv3d(num_classes, ndf, kernel_size=4, stride=2, padding=1),\n","        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","        nn.Conv3d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1),\n","        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","        nn.Conv3d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1),\n","        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","        nn.Conv3d(ndf * 4, 1, kernel_size=(2,3,2), stride=1, padding=0)\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"w88IQv-kFjba"},"source":["solver => build.py"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699085135058,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"5kqA7hxLFhpZ"},"outputs":[],"source":["#!/usr/bin/env python3\n","# encoding: utf-8\n","import torch\n","from torch.optim import lr_scheduler\n","\n","def make_optimizer_double(config, model1, model2):\n","    lr = float(config['lr'])\n","    print('initial learning rate is ', lr)\n","    optimizer = torch.optim.Adam([\n","    {'params': model1.parameters()},\n","    {'params': model2.parameters()}], lr=lr, weight_decay=float(config['weight_decay']))\n","    scheduler = PolyLR(optimizer, max_epoch=int(config['epochs']), power=float(config['power']))\n","\n","    return optimizer, scheduler\n","\n","\n","class PolyLR(lr_scheduler._LRScheduler):\n","    \"\"\"Set the learning rate of each parameter group to the initial lr decayed\n","    by gamma every epoch. When last_epoch=-1, sets initial lr as lr.\n","\n","    Args:\n","        optimizer (Optimizer): Wrapped optimizer.\n","        gamma (float): Multiplicative factor of learning rate decay.\n","        last_epoch (int): The index of last epoch. Default: -1.\n","    \"\"\"\n","\n","    def __init__(self, optimizer, max_epoch, power=0.9, last_epoch=-1):\n","        self.max_epoch = max_epoch\n","        self.power = power\n","        super(PolyLR, self).__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        return [base_lr * (1 - self.last_epoch / self.max_epoch) ** self.power\n","                for base_lr in self.base_lrs]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aFyXc2QeFsXq"},"source":["losses.py"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":535,"status":"ok","timestamp":1699085135591,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"7rKlPABTFqns"},"outputs":[],"source":["#!/usr/bin/env python3\n","# encoding: utf-8\n","# Modified from https://github.com/Wangyixinxin/ACN\n","import torch\n","from torch.nn import functional as F\n","import numpy as np\n","import numpy as np\n","from matplotlib import cm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","from PIL import Image\n","import cv2\n","import torch.nn as nn\n","\n","def sigmoid_rampup(current, rampup_length):\n","    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n","    if rampup_length == 0:\n","        return 1.0\n","    else:\n","        current = np.clip(current, 0.0, rampup_length)\n","        phase = 1.0 - current / rampup_length\n","        return float(np.exp(-5.0 * phase * phase))\n","\n","def get_current_consistency_weight(epoch, consistency = 10, consistency_rampup = 20.0):\n","    # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n","    return consistency * sigmoid_rampup(epoch, consistency_rampup)\n","\n","def bce_loss(y_pred, y_label):\n","    y_truth_tensor = torch.FloatTensor(y_pred.size())\n","    y_truth_tensor.fill_(y_label)\n","    y_truth_tensor = y_truth_tensor.to(y_pred.get_device())\n","    return nn.BCEWithLogitsLoss()(y_pred, y_truth_tensor)\n","\n","\n","def dice_loss(input, target):\n","    \"\"\"soft dice loss\"\"\"\n","    eps = 1e-7\n","    iflat = input.view(-1)\n","    tflat = target.view(-1)\n","    intersection = (iflat * tflat).sum()\n","\n","    return 1 - 2. * intersection / ((iflat ** 2).sum() + (tflat ** 2).sum() + eps)\n","\n","def gram_matrix(input):\n","    a, b, c, d, e = input.size()\n","    features = input.view(a * b, c * d * e)\n","    G = torch.mm(features, features.t())  # compute the gram product\n","    return G.div(a * b * c * d * e)\n","\n","def get_style_loss(sf, sm):\n","    g_f = gram_matrix(sf)\n","    g_m = gram_matrix(sm)\n","    channels = sf.size(1)\n","    size     = sf.size(2)*sf.size(3)\n","    sloss = torch.sum(torch.square(g_f-g_m)) / (4.0 * (channels ** 2) * (size ** 2))\n","    return sloss*0.0001\n","\n","def unet_Co_loss(config, batch_pred_full, content_full, batch_y, batch_pred_missing, content_missing, sf, sm, epoch):\n","    loss_dict = {}\n","    loss_dict['ed_dc_loss']  = dice_loss(batch_pred_full[:, 0], batch_y[:, 0])  # whole tumor\n","    loss_dict['net_dc_loss'] = dice_loss(batch_pred_full[:, 1], batch_y[:, 1])  # tumore core\n","    loss_dict['et_dc_loss']  = dice_loss(batch_pred_full[:, 2], batch_y[:, 2])  # enhance tumor\n","\n","    loss_dict['ed_miss_dc_loss']  = dice_loss(batch_pred_missing[:, 0], batch_y[:, 0])  # whole tumor\n","    loss_dict['net_miss_dc_loss'] = dice_loss(batch_pred_missing[:, 1], batch_y[:, 1])  # tumore core\n","    loss_dict['et_miss_dc_loss']  = dice_loss(batch_pred_missing[:, 2], batch_y[:, 2])  # enhance tumor\n","\n","    ## Dice loss predictions\n","    loss_dict['loss_dc'] = loss_dict['ed_dc_loss'] + loss_dict['net_dc_loss'] + loss_dict['et_dc_loss']\n","    loss_dict['loss_miss_dc'] = loss_dict['ed_miss_dc_loss'] + loss_dict['net_miss_dc_loss'] + loss_dict['et_miss_dc_loss']\n","\n","    ## Consistency loss\n","    loss_dict['ed_mse_loss']  = F.mse_loss(batch_pred_full[:, 0], batch_pred_missing[:, 0], reduction='mean')\n","    loss_dict['net_mse_loss'] = F.mse_loss(batch_pred_full[:, 1], batch_pred_missing[:, 1], reduction='mean')\n","    loss_dict['et_mse_loss']  = F.mse_loss(batch_pred_full[:, 2], batch_pred_missing[:, 2], reduction='mean')\n","    loss_dict['consistency_loss'] = loss_dict['ed_mse_loss'] + loss_dict['net_mse_loss'] + loss_dict['et_mse_loss']\n","\n","    ## Content loss\n","    loss_dict['content_loss'] = F.mse_loss(content_full, content_missing, reduction='mean')\n","\n","    ## Style loss\n","    sloss = get_style_loss(sf, sm)\n","\n","\n","    ## Weights for each loss the lamba values\n","    weight_content = float(config['weight_content'])\n","    weight_missing = float(config['weight_mispath'])\n","    weight_full    = 1 - float(config['weight_mispath'])\n","\n","    weight_consistency = get_current_consistency_weight(epoch)\n","    loss_dict['loss_Co'] = weight_full * loss_dict['loss_dc'] + weight_missing * loss_dict['loss_miss_dc'] + \\\n","                            weight_consistency * loss_dict['consistency_loss'] + weight_content * loss_dict['content_loss']+sloss\n","\n","    return loss_dict\n","\n","def get_losses(config):\n","    losses = {}\n","    losses['co_loss'] = unet_Co_loss\n","    return losses\n","\n","\n","class DiceLoss(torch.nn.Module):\n","    def __init__(self, smooth=1.0):\n","        super(DiceLoss, self).__init__()\n","        self.smooth = smooth\n","\n","    def forward(self, prediction, target):\n","        prediction = torch.Tensor(prediction)\n","        target = torch.Tensor(target)\n","        iflat = prediction.reshape(-1)\n","        tflat = target.reshape(-1)\n","        intersection = (iflat * tflat).sum()\n","\n","        return ((2.0 * intersection + self.smooth) / (iflat.sum() + tflat.sum() + self.smooth)).numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I5wAUGWOerVq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bnz6orR_Esg3"},"source":["train.ipynb\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1699085135592,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"EjOqz-lkHqbQ"},"outputs":[],"source":["#!/usr/bin/env python3\n","# encoding: utf-8\n","import os\n","import random\n","import torch\n","import warnings\n","import numpy as np\n","\n","def init_env(gpu_id='0', seed=42):\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_id\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.benchmark = True\n","    warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"O3Mv9kVsMdGL"},"source":["make_data_loader"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"QMCU-qxBIaBl","executionInfo":{"status":"ok","timestamp":1699085135592,"user_tz":-300,"elapsed":9,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}}},"outputs":[],"source":["## Config file\n","lr:              1e-4 # Initial learning rate\n","weight_decay:    1e-5\n","power:           0.9\n","epochs:          2 # Number of epochs to train the model\n","number_classes:  4 # Number of classes in the target dataset\n","batch_size_tr:   1 # Batch size for train\n","batch_size_va:   1 # Batch size for validationn\n","modalities:      ['flair', 't1', 't1ce', 't2']# List of modalities needd to be used for training and evaluating the model\n","path_to_data:    '/content/brats2018/MICCAI_BraTS_2018_Data_Training/' # path to dataset\n","path_to_log:     './results/' # path to save results\n","progress_p:      0.1 # value between 0-1 shows the number of time we need to report training progress in each epoch\n","validation_p:    0.1 # validation percentage\n","test_p:          0.2 # Test percentage (20%)\n","inputshape:      [160, 192, 128]\n","weight_mispath:  0.6\n","weight_content:  0.2"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"bTxZQXgeMalu","executionInfo":{"status":"ok","timestamp":1699085135592,"user_tz":-300,"elapsed":8,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}}},"outputs":[],"source":["def make_data_loaders(config):\n","    train_list, val_list = split_dataset(config['path_to_data'], float(config['test_p']))\n","    print(train_list)\n","    print(val_list)\n","    crop_size = np.zeros((3))\n","    crop_size[0] = config['inputshape'][0]\n","    crop_size[1] = config['inputshape'][1]\n","    crop_size[2] = config['inputshape'][2]\n","    crop_size    = crop_size.astype(np.uint16)\n","    crop_size    = (160, 192, 128)\n","    train_ds = Brats2018(train_list, crop_size=crop_size, modes=config['modalities'], train=True)\n","    val_ds = Brats2018(val_list,     crop_size=crop_size, modes=config['modalities'], train=False)\n","    loaders = {}\n","    loaders['train'] = DataLoader(train_ds, batch_size=int(config['batch_size_tr']),\n","                                  num_workers=4,\n","                                  pin_memory=True,\n","                                  shuffle=True)\n","    loaders['eval'] = DataLoader(val_ds, batch_size=int(config['batch_size_va']),\n","                                  num_workers=4,\n","                                  pin_memory=True,\n","                                  shuffle=False)\n","    return loaders\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1491,"status":"ok","timestamp":1699085195836,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"},"user_tz":-300},"id":"00zVlMFmGJ_C","outputId":"314d2517-015f-4e65-a9d2-3d00c42839db"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'lr': '1e-4', 'weight_decay': '1e-5', 'power': 0.9, 'epochs': 250, 'number_classes': 4, 'batch_size_tr': 1, 'batch_size_va': 1, 'modalities': ['flair', 't1', 't1ce', 't2'], 'path_to_data': '/content/brats2018/MICCAI_BraTS_2018_Data_Training/', 'path_to_log': './results/', 'progress_p': 0.1, 'validation_p': 0.1, 'test_p': 0.2, 'inputshape': [160, 192, 128], 'weight_mispath': 0.6, 'weight_content': 0.2}\n","['/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQU_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQV_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQY_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ARF_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ARW_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ARZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASA_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASE_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASK_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASU_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASV_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASW_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASY_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATD_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATF_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATV_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATX_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AUN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AUQ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AUR_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AVG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AVJ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AVV_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AWG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AWH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AWI_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXJ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXL_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXM_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXQ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXW_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AYA_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AYI_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AYU_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AYW_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AZD_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AZH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BFB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BFP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BHB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BHK_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BHM_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_131_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_147_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_150_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_180_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_186_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_190_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_201_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_203_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_221_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_231_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_235_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_335_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_378_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_390_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_401_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_411_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_412_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_425_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_429_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_448_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_460_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_499_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_117_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_118_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_135_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_151_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_168_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_171_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_179_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_198_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_208_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_222_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_226_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_274_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_283_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_290_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_300_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_309_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_314_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_321_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_322_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_331_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_368_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_370_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_374_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_377_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_394_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_430_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_455_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_471_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_473_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_491_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_605_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_606_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_607_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_608_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_121_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_133_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_138_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_199_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_257_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_265_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_296_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_338_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_375_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_419_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_474_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_498_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_111_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_149_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_192_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_328_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_343_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_361_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_437_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_479_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA05_277_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA05_396_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA05_444_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA05_478_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_165_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_184_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_211_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_247_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_332_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_372_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_409_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_603_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_105_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_113_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_162_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_167_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_205_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_218_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_234_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_242_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_278_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_280_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_319_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_406_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_436_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_469_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_0_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_15_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_16_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_1_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_24_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_28_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_29_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_6_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_8_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_9_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_141_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_177_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_254_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_255_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_312_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_402_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_428_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_451_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_462_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_493_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_620_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_103_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_109_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_130_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_152_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_175_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_202_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_241_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_261_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_266_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_276_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_282_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_299_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_307_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_310_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_325_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_330_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_346_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_351_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_387_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_393_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_408_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_410_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_413_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_420_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_442_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_449_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_490_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_625_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_628_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_629_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_632_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_637_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_639_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_640_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_644_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_101_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_249_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_298_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_466_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_470_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_480_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_615_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_618_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_621_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_623_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_624_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_630_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_633_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_634_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_642_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_645_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_650_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_653_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_654_1']\n","['/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_10_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_11_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_12_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_13_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_14_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_17_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_18_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_19_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_20_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_21_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_22_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_23_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_25_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_26_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_27_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_2_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_3_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_4_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_5_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_7_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AAB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AAG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AAL_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AAP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABE_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABM_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABY_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ALN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ALU_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ALX_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AME_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AMH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ANG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ANI_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ANP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ANZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOD_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_APR_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_APY_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_APZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQA_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQD_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQJ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQQ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQR_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQT_1']\n","initial learning rate is  0.0001\n"]}],"source":["\n","# The code is extensively uses the ACN implementation, please see:\n","## https://github.com/Wangyixinxin/ACN##\n","#!/usr/bin/env python3\n","# encoding: utf-8\n","import yaml\n","# from data import make_data_loaders\n","# from models import build_model\n","# from models.discriminator import get_style_discriminator\n","# from solver import make_optimizer_double\n","# from losses import get_losses, bce_loss, DiceLoss\n","import os\n","import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","# from utils import init_env\n","import nibabel as nib\n","import numpy as np\n","\n","\n","\n","\n","def load_old_model(model_full, model_missing, d_style, optimizer, saved_model_path):\n","    print(\"Constructing model from saved file... \")\n","    checkpoint = torch.load(saved_model_path)\n","    model_full.load_state_dict(checkpoint[\"model_full\"])\n","    model_missing.load_state_dict(checkpoint[\"model_missing\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","    d_style.load_state_dict(checkpoint[\"d_style\"])\n","    epoch = checkpoint[\"epochs\"]\n","\n","    return model_full, model_missing, d_style, optimizer, epoch\n","\n","def to_numpy(tensor):\n","    if isinstance(tensor, (int, float)):\n","        return tensor\n","    else:\n","        return tensor.data.cpu().numpy()\n","\n","\n","\n","\n","## Main section\n","config = yaml.load(open('/content/smunet/config.yml'), Loader=yaml.FullLoader)\n","init_env('0')\n","print(config)\n","loaders = make_data_loaders(config)\n","model_full, model_missing = build_model(inp_dim1 = 4, inp_dim2 = 1)\n","model_full    = model_full.cuda()\n","model_missing = model_missing.cuda()\n","d_style       = get_style_discriminator(num_classes = 128).cuda()\n","task_name = 'brats2018_flair'\n","log_dir = os.path.join(config['path_to_log'], task_name)\n","optimizer, scheduler = make_optimizer_double(config, model_full, model_missing)\n","losses = get_losses(config)\n","\n","continue_training = False\n","epoch = 0\n","\n","if not os.path.exists(log_dir):\n","    os.makedirs(log_dir)\n","\n","criteria = DiceLoss()\n","\n","\n","## evalute the performance\n","def get_mask(seg_volume):\n","    seg_volume = seg_volume.detach().cpu().numpy()\n","    seg_volume = np.squeeze(seg_volume)\n","    wt_pred = seg_volume[0]\n","    tc_pred = seg_volume[1]\n","    et_pred = seg_volume[2]\n","    mask = np.zeros_like(wt_pred)\n","    mask[wt_pred > 0.5] = 2\n","    mask[tc_pred > 0.5] = 1\n","    mask[et_pred > 0.5] = 4\n","    mask = mask.astype(\"uint8\")\n","    return mask\n","\n","def eval_metrics(gt, pred):\n","    loss_wt = criteria(np.where(gt>0, 1, 0), np.where(pred>0, 1, 0))\n","    loss_ct = criteria(np.where(gt==1, 1, 0)+np.where(gt==4, 1, 0), np.where(pred==1, 1, 0)+np.where(pred==4, 1, 0))\n","    loss_et = criteria(np.where(gt==4, 1, 0), np.where(pred==4, 1, 0))\n","    return loss_wt, loss_et, loss_ct\n","\n","def measure_dice_score(batch_pred, batch_y):\n","    pred = get_mask(batch_pred)\n","    gt   = get_mask(batch_y)\n","    loss_wt, loss_et, loss_ct = eval_metrics(gt, pred)\n","    score = (loss_wt+loss_et+loss_ct)/3.0\n","\n","    return score\n","\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442},"id":"g3MB3LXc5wCY","outputId":"d9ebc4f0-2e5e-45d5-d58b-d08be916744f","executionInfo":{"status":"error","timestamp":1699096617735,"user_tz":-300,"elapsed":18532,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}}},"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-16ef5357e86a>\u001b[0m in \u001b[0;36m<cell line: 105>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mmodel_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_old_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mtrain_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training process is finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-16ef5357e86a>\u001b[0m in \u001b[0;36mtrain_val\u001b[0;34m(model_full, model_missing, d_style, loaders, optimizer, scheduler, losses, epoch_init)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     \u001b[0mseg_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                     \u001b[0mseg_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'co_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-3d6d9dc378a1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0muout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0muout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-3d6d9dc378a1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mc1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             )\n\u001b[0;32m--> 605\u001b[0;31m         return F.conv3d(\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         )\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 8.81 MiB is free. Process 1874 has 14.73 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 103.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["\n","def train_val(model_full, model_missing, d_style, loaders, optimizer, scheduler, losses, epoch_init=0):\n","    n_epochs = int(config['epochs'])\n","    iter_num = 0\n","    best_dice = 0.0\n","    for epoch in range(epoch_init, n_epochs):\n","        scheduler.step()\n","        train_loss = 0.0\n","        val_scores_full = 0.0\n","        val_scores_miss = 0.0\n","\n","        for phase in ['train', 'eval']:\n","            loader = loaders[phase]\n","            total = len(loader)\n","            for batch_id, (batch_x, batch_y) in enumerate(loader):\n","                iter_num = iter_num + 1\n","                batch_x, batch_y = batch_x.cuda(non_blocking=True), batch_y.cuda(non_blocking=True)\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    seg_f, style_f, content_f = model_full(batch_x[:,0:])\n","                    seg_m, style_m, content_m = model_missing(batch_x[:,0:1])\n","                    loss_dict = losses['co_loss'](config, seg_f, content_f, batch_y, seg_m, content_m, style_f, style_m, epoch)\n","\n","                    d_style.train()\n","                    optimizer_d_style = optim.Adam(d_style.parameters(), lr = float(config['lr']), betas=(0.9, 0.99))\n","                    # labels for style adversarial training\n","                    source_label = 0\n","                    target_label = 1\n","\n","                    optimizer.zero_grad()\n","                    optimizer_d_style.zero_grad()\n","\n","                    # only train. Don't accumulate grads in disciminators\n","                    for param in d_style.parameters():\n","                        param.requires_grad = False\n","\n","                    if phase == 'train':\n","                        (loss_dict['loss_Co']).backward(retain_graph=True)\n","                        train_loss += loss_dict['loss_Co'].item()\n","\n","\n","\n","\n","                    ##################### adversarial training to fool the discriminator ######################\n","                    df_src_main = style_f\n","                    df_trg_main = style_m\n","                    d_df_out_main = d_style(df_trg_main)\n","                    loss_adv_df_trg_main = bce_loss(d_df_out_main, source_label)\n","                    loss = 0.0002 * loss_adv_df_trg_main\n","                    if phase == 'train':\n","                        loss.backward()\n","\n","\n","                    ####################### Train discriminator networks ######################################\n","                    # enable training mode on discriminator networks\n","                    for param in d_style.parameters():\n","                        param.requires_grad = True\n","                    df_src_main = df_src_main.detach()\n","                    d_df_out_main = d_style(df_src_main)\n","                    loss_d_feature_main = bce_loss(d_df_out_main, source_label)\n","                    if phase == 'train':\n","                        loss_d_feature_main.backward()\n","\n","                    ####################### train with target ##################################################\n","                    df_trg_main = df_trg_main.detach()\n","                    d_df_out_main = d_style(df_trg_main)\n","                    loss_d_feature_main = bce_loss(d_df_out_main, target_label)\n","\n","                    if phase == 'train':\n","                        loss_d_feature_main.backward()\n","\n","\n","                num_classes = 4\n","\n","                if phase == 'train':\n","                    optimizer.step()\n","                    optimizer_d_style.step()\n","                    if (batch_id + 1) % 20 == 0:\n","                        print(f'Epoch {epoch+1}>> itteration {batch_id+1}>> training loss>> {train_loss/(batch_id+1)}')\n","\n","                else:\n","                    val_scores_full += measure_dice_score(seg_f, batch_y)\n","                    val_scores_miss += measure_dice_score(seg_m, batch_y)\n","\n","            if phase == 'train':\n","                print(f'Epoch {epoch+1} overall training loss>> {train_loss/(batch_id+1)}')\n","            else:\n","                dice = (val_scores_miss/(batch_id+1))\n","                print(f'Epoch {epoch+1} validation dice score for missing modality>> {dice}')\n","                state = {}\n","                state['model_full'] = model_full.state_dict()\n","                state['model_missing'] = model_missing.state_dict()\n","                state['d_style'] = d_style.state_dict()\n","                state['optimizer'] = optimizer.state_dict()\n","                state['epochs'] = epoch\n","                file_name = log_dir+'/model_weights.pth'\n","                torch.save(state, file_name)\n","                if dice > best_dice:\n","                    torch.save(state, file_name)\n","                    best_dice = dice\n","\n","\n","\n","saved_model_path = log_dir+'/model_weights.pth'\n","if continue_training:\n","    model_full, model_missing, d_style, optimizer, epoch = load_old_model(model_full, model_missing, d_style, optimizer, saved_model_path)\n","train_val(model_full, model_missing, d_style, loaders, optimizer, scheduler, losses, epoch)\n","print('Training process is finished')\n"]},{"cell_type":"code","source":[],"metadata":{"id":"ficLiTSlFpCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UsSAKL1DFo_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"J0QyotiEFo8s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oZRP2OSqFo6R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Testing time"],"metadata":{"id":"KI2z6W1R1R67"}},{"cell_type":"markdown","metadata":{"id":"G9oMcypubo5v"},"source":["evolution.py"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"YFgm7i1MboH7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699098407464,"user_tz":-300,"elapsed":92415,"user":{"displayName":"Sana Ullah","userId":"07281496503381877384"}},"outputId":"2e335a61-a143-46d5-fa06-e2c3366c4e9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["['/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQU_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQV_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQY_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ARF_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ARW_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ARZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASA_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASE_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASK_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASU_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASV_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASW_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ASY_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATD_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATF_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATV_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ATX_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AUN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AUQ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AUR_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AVG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AVJ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AVV_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AWG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AWH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AWI_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXJ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXL_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXM_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXQ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AXW_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AYA_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AYI_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AYU_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AYW_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AZD_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AZH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BFB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BFP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BHB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BHK_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_BHM_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_131_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_147_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_150_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_180_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_186_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_190_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_201_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_203_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_221_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_231_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_235_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_335_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_378_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_390_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_401_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_411_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_412_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_425_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_429_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_448_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_460_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA01_499_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_117_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_118_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_135_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_151_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_168_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_171_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_179_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_198_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_208_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_222_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_226_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_274_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_283_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_290_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_300_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_309_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_314_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_321_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_322_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_331_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_368_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_370_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_374_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_377_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_394_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_430_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_455_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_471_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_473_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_491_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_605_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_606_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_607_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA02_608_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_121_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_133_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_138_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_199_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_257_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_265_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_296_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_338_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_375_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_419_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_474_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA03_498_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_111_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_149_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_192_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_328_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_343_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_361_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_437_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA04_479_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA05_277_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA05_396_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA05_444_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA05_478_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_165_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_184_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_211_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_247_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_332_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_372_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_409_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA06_603_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_105_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_113_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_162_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_167_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_205_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_218_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_234_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_242_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_278_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_280_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_319_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_406_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_436_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_TCIA08_469_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_0_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_15_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_16_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_1_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_24_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_28_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_29_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_6_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_8_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_2013_9_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_141_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_177_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_254_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_255_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_312_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_402_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_428_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_451_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_462_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_493_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA09_620_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_103_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_109_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_130_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_152_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_175_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_202_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_241_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_261_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_266_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_276_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_282_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_299_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_307_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_310_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_325_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_330_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_346_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_351_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_387_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_393_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_408_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_410_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_413_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_420_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_442_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_449_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_490_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_625_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_628_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_629_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_632_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_637_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_639_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_640_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA10_644_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_101_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_249_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_298_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_466_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_470_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA12_480_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_615_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_618_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_621_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_623_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_624_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_630_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_633_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_634_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_642_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_645_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_650_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_653_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/LGG/Brats18_TCIA13_654_1']\n","['/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_10_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_11_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_12_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_13_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_14_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_17_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_18_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_19_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_20_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_21_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_22_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_23_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_25_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_26_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_27_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_2_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_3_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_4_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_5_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_7_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AAB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AAG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AAL_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AAP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABB_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABE_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABM_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ABY_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ALN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ALU_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ALX_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AME_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AMH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ANG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ANI_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ANP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_ANZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOD_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOH_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AOZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_APR_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_APY_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_APZ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQA_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQD_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQG_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQJ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQN_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQO_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQP_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQQ_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQR_1', '/content/brats2018/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_CBICA_AQT_1']\n","50\n","Constructing model from saved file... \n"," validation Dise score full modalities class>> whole: 0.8400278870473828 core:0.7604809708305096  enh:0.6916992426114646\n"," validation Dise score missing modality  class>> whole: 0.7952979348207775 core:0.48179751994055614  enh:0.3166744250215982\n"]}],"source":["\n","#!/usr/bin/env python3\n","# encoding: utf-8\n","import yaml\n","# from data import make_data_loaders\n","# from models import build_model\n","# from models.discriminator import get_style_discriminator\n","# from solver import make_optimizer_double\n","# from losses import get_losses, bce_loss, DiceLoss\n","import os\n","import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","# from utils import init_env\n","import nibabel as nib\n","import numpy as np\n","def load_old_model(model_full, model_missing, saved_model_path):\n","    print(\"Constructing model from saved file... \")\n","    checkpoint = torch.load(saved_model_path)\n","    model_full.load_state_dict(checkpoint[\"model_full\"])\n","    model_missing.load_state_dict(checkpoint[\"model_missing\"])\n","\n","    return model_full, model_missing\n","\n","def to_numpy(tensor):\n","    if isinstance(tensor, (int, float)):\n","        return tensor\n","    else:\n","        return tensor.data.cpu().numpy()\n","\n","def eval_metrics(gt, pred):\n","    loss_hw = criteria(np.where(gt>0, 1, 0), np.where(pred>0, 1, 0))\n","    loss_ed = criteria(np.where(gt==1, 1, 0)+np.where(gt==4, 1, 0), np.where(pred==1, 1, 0)+np.where(pred==4, 1, 0))\n","    loss_ct = criteria(np.where(gt==4, 1, 0), np.where(pred==4, 1, 0))\n","    return (loss_hw, loss_ed, loss_ct)\n","\n","\n","def evaluate_sample(batch_pred_full, batch_pred_missing, batch_y):\n","    def get_mask(seg_volume):\n","        seg_volume = seg_volume.cpu().numpy()\n","        seg_volume = np.squeeze(seg_volume)\n","        wt_pred = seg_volume[0]\n","        tc_pred = seg_volume[1]\n","        et_pred = seg_volume[2]\n","        mask = np.zeros_like(wt_pred)\n","        TH = 0.4\n","        mask[wt_pred >= TH] = 2\n","        mask[tc_pred >= TH] = 1\n","        mask[et_pred >= TH] = 4\n","        mask = mask.astype(\"uint8\")\n","        #mask_nii = nib.Nifti1Image(mask, np.eye(4))\n","        return mask\n","\n","    pred_nii_full = get_mask(batch_pred_full)\n","    pred_nii_miss = get_mask(batch_pred_missing)\n","    gt_nii = get_mask(batch_y)\n","\n","    metric_full  = eval_metrics(gt_nii, pred_nii_full)\n","    metric_miss  = eval_metrics(gt_nii, pred_nii_miss)\n","\n","    return metric_full, metric_miss\n","## Main section\n","config = yaml.load(open('/content/smunet/config.yml'), Loader=yaml.FullLoader)\n","init_env('0')\n","loaders = make_data_loaders(config)\n","model_full, model_missing = build_model(inp_dim1 = 4, inp_dim2 = 1)\n","model_full    = model_full.cuda()\n","model_missing = model_missing.cuda()\n","d_style = get_style_discriminator(num_classes = 128).cuda()\n","task_name = 'brats2018_flair'\n","log_dir = os.path.join(config['path_to_log'], task_name)\n","criteria = DiceLoss()\n","def evaluate_performance(model_full, model_missing, loaders):\n","    class_score_full  = np.array((0.,0.,0.))\n","    class_score_mono  = np.array((0.,0.,0.))\n","    loader = loaders['eval']\n","    total = len(loader)\n","    with torch.no_grad():\n","        for batch_id, (batch_x, batch_y) in enumerate(loader):\n","            batch_x, batch_y = batch_x.cuda(non_blocking=True), batch_y.cuda(non_blocking=True)\n","            seg_f, style_f, content_f = model_full(batch_x[:,:])\n","            seg_m, style_m, content_m = model_missing(batch_x[:,0:1])\n","            metric_full, metric_miss = evaluate_sample(seg_f, seg_m, batch_y)\n","            class_score_full += metric_full\n","            class_score_mono += metric_miss\n","\n","\n","    class_score_full  /= total\n","    class_score_mono /= total\n","    print(f' validation Dise score full modalities class>> whole: {class_score_full[0]} core:{class_score_full[1]}  enh:{class_score_full[2]}')\n","    print(f' validation Dise score missing modality  class>> whole: {class_score_mono[0]} core:{class_score_mono[1]}  enh:{class_score_mono[2]}')\n","\n","\n","saved_model_path ='/content/results/brats2018_flair/model_weights.pth'\n","print(len(saved_model_path))\n","model_full, model_missing = load_old_model(model_full, model_missing, saved_model_path)\n","evaluate_performance(model_full, model_missing, loaders)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kvtHu7LXbxGw"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"NTp02NWqNV9M"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}